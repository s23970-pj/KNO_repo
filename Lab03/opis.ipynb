{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aby zrealizować to zadanie, postępujemy według następujących kroków:\n",
    "\n",
    "### Krok 1: Przygotowanie zbioru danych\n",
    "1. **Pobranie i załadowanie danych**:\n",
    "   - Ściągamy dane z [podanego źródła UCI Wine Dataset](http://archive.ics.uci.edu/dataset/109/wine).\n",
    "   - Ładujemy dane z pliku CSV przy pomocy bibliotek takich jak `pandas` lub `numpy`.\n",
    "\n",
    "2. **Przetasowanie zbioru**:\n",
    "   - Przetasujemy dane, aby zapewnić losowe rozmieszczenie przykładów z każdej z 3 kategorii, co jest istotne dla poprawnego trenowania i walidacji modelu.\n",
    "\n",
    "3. **Kodowanie kategorii**:\n",
    "   - Kategoria wina zostanie zakodowana w formie \"one-hot encoding\" przy użyciu funkcji `np.eye()` lub narzędzia z biblioteki `pandas` – `pd.get_dummies()`, aby każda kategoria była reprezentowana w formie wektora (np. `[1,0,0]`, `[0,1,0]`, `[0,0,1]`).\n",
    "\n",
    "### Krok 2: Przygotowanie modelu i funkcji celu\n",
    "1. **Funkcja celu i aktywacja wyjścia**:\n",
    "   - Ponieważ mamy do czynienia z klasyfikacją wieloklasową, najlepszą funkcją celu jest `categorical_crossentropy`, a funkcją aktywacji na wyjściu – `softmax`, która konwertuje wynik na prawdopodobieństwa przynależności do danej kategorii.\n",
    "\n",
    "2. **Tworzenie modeli w Kerasie**:\n",
    "   - **Model 1**: Sequential z podstawową liczbą warstw.\n",
    "   - **Model 2**: Sequential z bardziej zaawansowaną konfiguracją (np. inną liczbą warstw, funkcjami aktywacji i metodami inicjalizacji wag).\n",
    "   - W obu modelach podajemy dodatkowe informacje, takie jak nazwy warstw.\n",
    "\n",
    "### Krok 3: Trening i testowanie modelu\n",
    "1. **Podział zbioru danych**:\n",
    "   - Podzielimy zbiór na część treningową i testową (np. 80% do treningu, 20% do testów).\n",
    "\n",
    "2. **Parametry treningu**:\n",
    "   - Określimy `learning_rate`, `batch_size`, oraz liczbę `epok`, które będą spójne między modelami.\n",
    "\n",
    "3. **Uczenie i analiza wyników w TensorBoard**:\n",
    "   - Podczas trenowania modeli, uruchomimy TensorBoard, aby śledzić krzywe uczenia (loss, accuracy) oraz obserwować konwergencję obu modeli.\n",
    "\n",
    "4. **Wyniki i wnioski**:\n",
    "   - Porównamy oba modele na podstawie wyników (dokładności, przebiegu krzywych uczenia).\n",
    "   - Wyciągniemy wnioski, który model lepiej się sprawdził i jakie mogą być przyczyny tej różnicy (np. nadmierne dopasowanie, stabilność konwergencji, struktura sieci).\n",
    "\n",
    "### Krok 4: Przygotowanie programu interaktywnego\n",
    "Po wytrenowaniu najlepszego modelu przygotujemy prosty interfejs, który:\n",
    "1. Pozwala użytkownikowi wprowadzić wartości cech wina (atrybuty z zestawu danych).\n",
    "2. Przetwarza wejście przez model, aby uzyskać kategorię wina w postaci liczby (np. 1, 2, lub 3).\n",
    "3. Przykład kodu dla użytkownika:\n",
    "   ```python\n",
    "   # User inputs for wine characteristics\n",
    "   wine_characteristics = np.array([[13.2, 2.77, 2.51, 18.5, 98, 2.64, 2.43, 0.26, 1.63, 5.4, 0.94, 3.17, 680]])\n",
    "   prediction = model.predict(wine_characteristics)\n",
    "   predicted_class = np.argmax(prediction) + 1\n",
    "   print(f\"Predicted wine category: {predicted_class}\")\n",
    "   ```\n",
    "\n",
    "### Dokumentacja i opis wyników\n",
    "1. **Opis modeli**:\n",
    "   - Krótki opis struktury, liczby warstw i użytych funkcji aktywacji.\n",
    "   \n",
    "2. **Wyniki i analiza**:\n",
    "   - Dołączamy krzywe uczenia i dokładność modeli.\n",
    "   - Krótka interpretacja wyników – który model lepiej sobie radzi i dlaczego.\n",
    "\n",
    "3. **Wnioski końcowe**:\n",
    "   - Opisujemy, jaki model był bardziej skuteczny i potencjalne przyczyny tego efektu (np. głębsza sieć może być bardziej podatna na przetrenowanie, a płytka może nie oddać pełnej złożoności danych).\n",
    "\n",
    "Pamiętaj, aby zapisać projekt jako notatnik lub plik Python, wraz z dokumentacją krzywych uczenia i opisem wyników."
   ],
   "id": "b3f78bfc378b0599"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Oto kompletny kod Python, który realizuje Twoje zadanie krok po kroku:\n",
    "\n",
    "Krok 1: Przygotowanie zbioru danych"
   ],
   "id": "c35b9e70253f3def"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Pobranie danych\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "columns = ['Class', 'Alcohol', 'Malic_acid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', \n",
    "           'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins', \n",
    "           'Color_intensity', 'Hue', 'OD280/OD315', 'Proline']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Przetasowanie danych\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Oddzielenie cech od etykiet\n",
    "X = data.drop('Class', axis=1).values\n",
    "y = data['Class'].values.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding etykiet\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a0c9cd55fe5803d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Krok 2: Definicja modeli\n",
    "Poniżej znajdują się dwie różne architektury modelu.\n",
    "\n",
    "Model 1"
   ],
   "id": "d9d90092fb8a1860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model 1 - Prosta architektura\n",
    "model_1 = Sequential(name=\"Model_1\")\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), name=\"Hidden_Layer_1\"))\n",
    "model_1.add(Dense(32, activation='relu', name=\"Hidden_Layer_2\"))\n",
    "model_1.add(Dense(3, activation='softmax', name=\"Output_Layer\"))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n"
   ],
   "id": "65fc75223d6bfe46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model 2",
   "id": "c8b214c1e66889ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model 2 - Rozszerzona architektura\n",
    "model_2 = Sequential(name=\"Model_2\")\n",
    "model_2.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), name=\"Hidden_Layer_1\"))\n",
    "model_2.add(Dense(64, activation='relu', name=\"Hidden_Layer_2\"))\n",
    "model_2.add(Dense(32, activation='relu', name=\"Hidden_Layer_3\"))\n",
    "model_2.add(Dense(3, activation='softmax', name=\"Output_Layer\"))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n"
   ],
   "id": "c66d6ed0fe2c3ced"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Krok 3: Trening modeli i TensorBoard",
   "id": "89ad0d572b85413d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ustawienia TensorBoard\n",
    "log_dir_1 = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_model_1\"\n",
    "tensorboard_callback_1 = TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "\n",
    "log_dir_2 = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_model_2\"\n",
    "tensorboard_callback_2 = TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "\n",
    "# Trening modelu 1\n",
    "history_1 = model_1.fit(X_train, y_train, \n",
    "                        epochs=100, \n",
    "                        batch_size=32, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        callbacks=[tensorboard_callback_1])\n",
    "\n",
    "# Trening modelu 2\n",
    "history_2 = model_2.fit(X_train, y_train, \n",
    "                        epochs=100, \n",
    "                        batch_size=32, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        callbacks=[tensorboard_callback_2])\n"
   ],
   "id": "73475e39094c2389"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Krok 4: Ocena modeli i wybór najlepszego",
   "id": "20a9aff8b6084532"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ocena modelu 1\n",
    "test_loss_1, test_acc_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Model 1 - Test accuracy: {test_acc_1:.4f}\")\n",
    "\n",
    "# Ocena modelu 2\n",
    "test_loss_2, test_acc_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Model 2 - Test accuracy: {test_acc_2:.4f}\")\n",
    "\n",
    "# Wybór najlepszego modelu\n",
    "best_model = model_1 if test_acc_1 > test_acc_2 else model_2\n"
   ],
   "id": "fd3597665201b378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Krok 5: Interaktywny model predykcji dla użytkownika",
   "id": "1e15aa8e52186626"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Funkcja predykcyjna dla użytkownika\n",
    "def predict_wine_category(features):\n",
    "    prediction = best_model.predict(np.array([features]))\n",
    "    predicted_class = np.argmax(prediction) + 1\n",
    "    return predicted_class\n",
    "\n",
    "# Przykład użycia\n",
    "user_input = np.array([13.2, 2.77, 2.51, 18.5, 98, 2.64, 2.43, 0.26, 1.63, 5.4, 0.94, 3.17, 680])\n",
    "print(f\"Predicted wine category: {predict_wine_category(user_input)}\")\n"
   ],
   "id": "c30b06c1f75f91c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Krok 6: Analiza wyników i TensorBoard\n",
    "W celu analizy wyników należy uruchomić TensorBoard:"
   ],
   "id": "4c3c3e69fd38a38c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tensorboard --logdir=logs/fit\n",
   "id": "62521cba1194b5d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Oto kompletny kod Python, który realizuje Twoje zadanie krok po kroku:\n",
    "\n",
    "### Krok 1: Przygotowanie zbioru danych\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Pobranie danych\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "columns = ['Class', 'Alcohol', 'Malic_acid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', \n",
    "           'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins', \n",
    "           'Color_intensity', 'Hue', 'OD280/OD315', 'Proline']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Przetasowanie danych\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Oddzielenie cech od etykiet\n",
    "X = data.drop('Class', axis=1).values\n",
    "y = data['Class'].values.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding etykiet\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "### Krok 2: Definicja modeli\n",
    "\n",
    "Poniżej znajdują się dwie różne architektury modelu.\n",
    "\n",
    "#### Model 1\n",
    "\n",
    "```python\n",
    "# Model 1 - Prosta architektura\n",
    "model_1 = Sequential(name=\"Model_1\")\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), name=\"Hidden_Layer_1\"))\n",
    "model_1.add(Dense(32, activation='relu', name=\"Hidden_Layer_2\"))\n",
    "model_1.add(Dense(3, activation='softmax', name=\"Output_Layer\"))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "#### Model 2\n",
    "\n",
    "```python\n",
    "# Model 2 - Rozszerzona architektura\n",
    "model_2 = Sequential(name=\"Model_2\")\n",
    "model_2.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), name=\"Hidden_Layer_1\"))\n",
    "model_2.add(Dense(64, activation='relu', name=\"Hidden_Layer_2\"))\n",
    "model_2.add(Dense(32, activation='relu', name=\"Hidden_Layer_3\"))\n",
    "model_2.add(Dense(3, activation='softmax', name=\"Output_Layer\"))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### Krok 3: Trening modeli i TensorBoard\n",
    "\n",
    "```python\n",
    "# Ustawienia TensorBoard\n",
    "log_dir_1 = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_model_1\"\n",
    "tensorboard_callback_1 = TensorBoard(log_dir=log_dir_1, histogram_freq=1)\n",
    "\n",
    "log_dir_2 = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_model_2\"\n",
    "tensorboard_callback_2 = TensorBoard(log_dir=log_dir_2, histogram_freq=1)\n",
    "\n",
    "# Trening modelu 1\n",
    "history_1 = model_1.fit(X_train, y_train, \n",
    "                        epochs=100, \n",
    "                        batch_size=32, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        callbacks=[tensorboard_callback_1])\n",
    "\n",
    "# Trening modelu 2\n",
    "history_2 = model_2.fit(X_train, y_train, \n",
    "                        epochs=100, \n",
    "                        batch_size=32, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        callbacks=[tensorboard_callback_2])\n",
    "```\n",
    "\n",
    "### Krok 4: Ocena modeli i wybór najlepszego\n",
    "\n",
    "```python\n",
    "# Ocena modelu 1\n",
    "test_loss_1, test_acc_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Model 1 - Test accuracy: {test_acc_1:.4f}\")\n",
    "\n",
    "# Ocena modelu 2\n",
    "test_loss_2, test_acc_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Model 2 - Test accuracy: {test_acc_2:.4f}\")\n",
    "\n",
    "# Wybór najlepszego modelu\n",
    "best_model = model_1 if test_acc_1 > test_acc_2 else model_2\n",
    "```\n",
    "\n",
    "### Krok 5: Interaktywny model predykcji dla użytkownika\n",
    "\n",
    "```python\n",
    "# Funkcja predykcyjna dla użytkownika\n",
    "def predict_wine_category(features):\n",
    "    prediction = best_model.predict(np.array([features]))\n",
    "    predicted_class = np.argmax(prediction) + 1\n",
    "    return predicted_class\n",
    "\n",
    "# Przykład użycia\n",
    "user_input = np.array([13.2, 2.77, 2.51, 18.5, 98, 2.64, 2.43, 0.26, 1.63, 5.4, 0.94, 3.17, 680])\n",
    "print(f\"Predicted wine category: {predict_wine_category(user_input)}\")\n",
    "```\n",
    "\n",
    "### Krok 6: Analiza wyników i TensorBoard\n",
    "\n",
    "W celu analizy wyników należy uruchomić TensorBoard:\n",
    "```bash\n",
    "tensorboard --logdir=logs/fit\n",
    "```\n",
    "Następnie można przejść do przeglądarki i śledzić krzywe uczenia dla obu modeli, aby lepiej zrozumieć ich zachowanie podczas treningu.\n",
    "\n",
    "### Podsumowanie\n",
    "\n",
    "1. **Krzywe uczenia i dokładność**: Obserwuj krzywe uczenia obu modeli na TensorBoard, aby zobaczyć, jak zmienia się `accuracy` i `loss`.\n",
    "2. **Opis modeli**: Wybierz model z najlepszym wynikiem na zbiorze testowym i zwróć uwagę, czy liczba warstw oraz rozmiar warstw wpłynęły na ich skuteczność.\n",
    "3. **Predykcja**: Przygotowany interfejs predykcyjny pozwala na sprawdzenie kategorii wina na podstawie wprowadzonych cech.\n",
    "\n",
    "To kompletny kod do załadowania, przetworzenia, treningu oraz oceny modeli klasyfikacyjnych na zbiorze danych \"Wine\" – zgodnie z wymaganiami zadania."
   ],
   "id": "108dd0b926307613"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
